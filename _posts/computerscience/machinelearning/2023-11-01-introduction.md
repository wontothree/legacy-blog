---
title: "[Machine Learning] Introduction"
excerpt: "Ilseok Oh - Machine Learning : Ch01"
categories:
  - machinelearning
---
## 1. 기계학습이란

- 학습 : 경험의 결과로 나타나는 비교적 지속적인 행동의 변화나 그 잠재력의 변화. 또는 지식을 습득하는 과정
- 기계 학습 : 특정한 응용 영역에서 발생하는 데어터(경험)를 이용하여 높은 성능으로 문제를 해결하는 컴퓨터 프로그램을 만드는 작업
- 인공지능 : 컴퓨터에 지능을 부여하는 것

인공지능의 주도권은 지식기반 방식에서 기계 학습으로 넘어갔다.

- 지식기반(규칙기반) 방식 : 사람이 인식할 때 사용할 것으로 보이는 지식을 추려 프로그램에 심는 접근 방식
- 기계학습 : 데이터를 중심으로 하는 접근 방식

기계 학습은 예측 문제를 풀며, 예측에는 회귀와 분류가 있다.

- 회귀 : 실숫값을 예측하는 문제
- 분류 : 부류를 예측하는 문제

기계학습에서 데이터는 특징과 목푯값으로 이루어진다. 특징은 2개 이상의 특징으로 구성되는 벡터 형태를 갖는다.

$$
\mathbf{x}_1, \mathbf{x}_2, ... , \mathbf{x}_n
\\
y_1, y_2, ... , y_n
$$

학습 집합(훈련 집합)은 이 값들의 쌍이다. 

$$
X = \{\mathbf{x}_1, \mathbf{x}_2, ... , \mathbf{x}_n\}, Y = \{y_1, y_2, ..., y_n\}
$$

- 사례(샘플) : 훈련 집합의 요소
- 사례의 개수 : n

만약 훈련 집합의 네 점이 직선을 이룬다면 기계 학습에서는 이러한 의사결정을 모델로 직선을 선택했다고 한다.

- 기계 학습이란 가장 정확하게 예측할 수 있는, 즉 최적의 매개변숫값을 찾는 작업
- 학습(훈련) : 성능을 개선하면서 최적의 상태에 도달하는 작업
- 테스트 : 훈련 집합에 없는 새로운 샘플에 대한 목푯값을 예측하는 과정
- 테스트 집합 : 새로운 샘플을 가진 데이터
- 일반화 능력 : 테스트 집합에 대해 높은 성능을 가진 성질
- 데이터 베이스 : 훈련집합과 테스트 집합의 합

기계 학습의 최종 목표는 훈련 집합에 없는 새로운 샘플에 대한 오류를 최소화하는 것

사람의 학습과 기계 학습의 비교

|사람의 학습|비교 기준|기계 학습|
|:---:|:---:|:---:|
|능동적|학습 과정|수동적|
|자연에 존재하는 그대로|데이터 형식|일정한 형식에 맞추어 사람이 준비함|
|자연스럽게 여러 과업을 학습|동시에 학습 가능한 과업 수|하나의 과업만 가능|
|매우 제한적으로 알려져 있음|학습 원리에 대한 지식|모든 과정이 밝혀져 있음|
|매우 낮음|수학 의존도|매우 높음|
|경우에 따라 객관적이거나 주관적|성능 평가|객관적(수치로 평가, 예를 들어 정확률 99.8%)|
|수백만 년|역사|60년|

## 2. 특징 공간에 대한 이해

MNIST 데이터베이스는 필기 숫자를 필기 숫자를 제공하는데, 샘플을 28 x 28 크기의 비트맵으로 표현한다. 따라서 784개의 화소가 784차원의 특징 공간을 형성한다.

차원이 증가하면 모델의 매개변수 개수가 함께 증가한다.

d 차원 데이터

$$
\mathbf{x} = \{x_1, x_2, ... , x_n\}
$$

모델

$$
y = w_1x_1 + w_2x_2 + ... + w_dx_d + b
$$

2차원 곡선을 모델로 선택한다면 매개변수의 개수는 더 증가한다.

$$
y = w_1x_1^2 + w_2x_2 + b
\\
y = w_1x_1^2 + w_2x_2^2 + ... + w_dw_d^2 + w_{d+1}x_1x_2 + ... + w_{d^2}x_{d-1}x_d+w_{d^2+1}x_1 + ... + w_{d^2+d}x_d + b
$$

- 표현 학습 : 기계 학습에서 좋은 특징 공간을 찾아내는 작업

딥러닝은 신경망 구조에 여러 은닉층을 두고, 왼쪽 은닉층에서는 저급 특징을 추출하고 오른쪽으로 갈수록 고급 특징을 추출한다. 예를 들어, 영상을 인식할 때 모든 영상에 공통으로 나타나는 에지나 구석점 등이 저급 특징에 해당하고, 저급 특징이 결합한 얼굴이나 바퀴 등이 고급 특징에 해당한다. 이때 신경망 학습 알고리즘이 특징 공간 변환 공식을 자동으로 찾아내 이러한 계층적인 특징 추출 기능을 부여한다.

기계학습에서는 저차원에서 고안된 식 또는 알고리즘을 그대로 고차원에 적용할 수 있다.

- 차원의 저주 : 차원이 높아지면서 거대한 특징 공간이 형성되어 발생하는 문제

## 3. 데이터에 대한 이해

인식 문제를 풀기 위해서는 충분히 많은 데이터를 수집한 후 기계 학습 알고리즘에 입력하여 자동으로 모델을 찾아내게 하는 수밖에 없다.

기계 학습에서는 데이터 생성 과정을 전혀 모른다. 기계 학습은 훈련 집합을 이용하여 예측 모델 또는 생성 모델을 근사, 추정할 수 있을 뿐이다.

기계 학습에서는 주어진 응용 환경에 맞는 데이터베이스를 확보하는 일이 무엇보다 중요하다.

4차원 이상의 공간(초공간)에는 데이터를 그려 넣을 수 없다.

데이터 가시화는 모델 선택, 학습 알고리즘 선택 등 중요한 의사결정에 큰 도움이 된다.

## 4. 간단한 기계학습의 예

선형 회귀 : 선형 모델을 사용하여 회귀 문제를 푸는 기계 학습 알고리즘

기계학습에서 해야 할 일에 대한 수학적 과정

$$
\hat\theta = argmin_{\theta} J(\theta)
$$

- 수치적 방법 : 작은 개선을 반복하여 최적해를 찾아가는 방법
- 분석적 방법(해석적 방법) : 유도한 식에 훈련집합의 샘플을 대입하여 한꺼번에 최적해를 구하는 방식

기계 학습 알고리즘은 목적함수값이 작아지는 방향을 찾아 매개변수값을 조정하는 일을 반복한다. 목적함수가 0에 아주 가까운 값으로 수렴하면 학습을 마친다.

## 5. 모델 선택

### 과소적합과 과잉적합

- 과소적합 : 모델의 용량이 작아서 기계학습이 최적해를 찾더라도 큰 오차가 생기는 현상
- 과잉적합 : 훈련집합은 완벽에 가깝게 대변하지만 새로운 점을 제대로 대처하지 못하는 현상

### 바이어스와 분산

- 일반화 능력 : 훈련집합에 없는 새로운 데이터, 즉 테스트집합에 대해 높은 성능을 보장하는 프로그램을 만드는 것(기계 학습의 목표)

단순한 모델일수록 바이어스는 크고 분산은 작다.

복잡한 모델일수록 바이어스는 작고 분산은 크다.(훈련집합이 바뀔 때마다 모양이 크게 요동친다.)

기계 학습의 목표는 낮은 바이어스와 낮은 분산을 가진 예측기를 만드는 것이다. 바이어스와 분산은 하나를 낮추면 다른 것이 높아지는 트레이드 오프 성질이 있다. 따라서 바이어스의 희생을 최소로 유지하면서 분산을 최대로 낮추는 전략을 써야 한다.

### 검증집합과 교차검증을 이용한 모델 선택 알고리즘

검증집합 : 모델을 비교하는 데 사용할 별도의 데이터

k-겹 교차검증

1. 훈련집합을 같은 크기로 나누어 k개의 그룹을 만든다.
2. 그룹을 1개 남기고 k-1개로 모델을 학습시킨 후 남긴 그룹으로 성능을 평가한다.
3. 남기는 그룹을 달리하면서 이 과정을 k번 반복하여 k개의 성능을 얻는다.
4. 이를 평균하여 검증 성능을 취한다.

### 모델 선택의 한계와 현실적인 해결책

실제 세상에서 발생한 고차원 데이터에서는 다항식 모델을 사용하지 않는다. 다양한 신경망, 강화 학습, 확률 그래피컬 모댈, SVM, 트리 분류기 등을 사용한다.

실제로는 주로 경험 지식을 통해 큰 틀을 선택하고 그 틀 안에서 세부 모델을 선택하는 전략을 사용한다. 현대 기계 학습은 용량이 충분히 큰 모델을 선택한 후, 선택한 모델이 정상을 벗어나지 않도록 여러 규제 기법을 적용하는 현실적인 접근 방법을 채택한다.

## 6. 규제

## 7. 기계학습 유형

## 8. 기계학습의 과거와 현재, 미래