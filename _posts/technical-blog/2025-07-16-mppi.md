---
title: "[Control] MPPI: Theorically Grounded and Practically Effective"
categories:
  - technical-blog
---
1. Model predictive control algorithm based on the path integral control framework
2. generate new trajectories in real-time
3. based on a stochastic optimal control framework using a fundamental relationship between the information theoretic notions of free energy and relative entropy.
4. Not split the problem into a planning and execution phase, which allows for a simple problem formulation and optimal behavior with respect to the system dynamics.
5. Gradient-free

# Dynamics

## Continuous form

We consider SDE dynamics affine in control and subject to an affine Brownian disturbance

$$
d\boldsymbol{x} = \left( f(\boldsymbol{x}_t, t) + G(\boldsymbol{x}_t, t) \boldsymbol{u}_t(\boldsymbol{x}_t, t) \right) dt + B(\boldsymbol{x}_t, t) d\boldsymbol{w}
$$

where

- $\boldsymbol{x}_t = \boldsymbol{x}(t) \in \mathbb{R}^n$ : state of a dynamical system at time $t$
- $\boldsymbol{u}(\boldsymbol{x}_t, t) \in \mathbb{R}^m$ : control input for the system
- $\tau: [t_0, T] \rightarrow \mathbb{R}^n$ : trajectory of the system
- $d\boldsymbol{w} \in \mathbb{R}^p$ : Brownian disturbance

We assume that

$$
G(\mathbb{x}_t, t) =
\begin{bmatrix}
  0_{l \times m} \\
  G_c(\mathbb{x}_t, t) \\
\end{bmatrix},
\quad

B(\mathbb{x}_t, t) =
\begin{bmatrix}
  0_{l \times p} \\
  B_c(\mathbb{x}_t, t) \\
\end{bmatrix},
\quad

f(\mathbb{x}_t, t) =
\begin{bmatrix}
  f_a(\mathbb{x}_t, t) \\
  f_c(\mathbb{x}_t, t) \\
\end{bmatrix},
\quad

\mathbb{x}_t =
\begin{bmatrix}
  \mathbb{x}_t^{(a)} \\
  \mathbb{x}_t^{(c)} \\
\end{bmatrix}
$$

where

$$
G_c(\boldsymbol{x}_t, t): \mathbb{R}^n \times \mathbb{R}^+ \rightarrow \mathbb{R}^{(n-l) \times m}, 

\quad B_c(\boldsymbol{x}_t, t): \mathbb{R}^n \times \mathbb{R}^+ \rightarrow \mathbb{R}^{(n-l) \times p},
\\

\quad f_a(\boldsymbol{x}_t, t): \mathbb{R}^n \times \mathbb{R}^+ \rightarrow \mathbb{R}^{l \times l}

\quad f_n(\boldsymbol{x}_t, t): \mathbb{R}^n \times \mathbb{R}^+ \rightarrow \mathbb{R}^{(n-l) \times l}
\\
\boldsymbol{x}_t^{(a)} \in \mathbb{R}^l,
\quad \boldsymbol{x}_t^{(c)} \in \mathbb{R}^{n-l},
$$

This state–space formulation can represent a large class of dynamical systems operating under the presence of stochastic forces.

## Discretized form

Dynamics for very general class of system

$$
\boldsymbol{x}_{t+1} = \boldsymbol{x}_t + d\boldsymbol{x}_t
$$

where

$$
d\boldsymbol{x}_t = \left( f(\boldsymbol{x}_t, t) + G(\boldsymbol{x}_t, t) \, \boldsymbol{u}(\boldsymbol{x}_t, t) \right) \, \Delta t + B(\boldsymbol{x}_t, t) \, \varepsilon \, \sqrt{\Delta t}
$$

<br>

Uncontrolled dynamics of the system

$$
d\boldsymbol{x}_t = f(\boldsymbol{x}_t, t) \Delta t + B(\boldsymbol{x}_t, t) \, \varepsilon \, \sqrt{\Delta t}
$$

or

$$
B(\boldsymbol{x}_t, t) d\boldsymbol{w} \approx d\boldsymbol{x}_t - f(\boldsymbol{x}_t, t) \Delta t
$$

## Special form

A special case used in original mppi implementation

$$
\begin{aligned}
d\boldsymbol{x}_t 
&= f(\boldsymbol{x}_t, t) \Delta t +  G(\boldsymbol{x}_t, t) \left( \boldsymbol{u}(\boldsymbol{x}_t, t) 
+ \dfrac{1}{\sqrt{\rho}} \dfrac{\epsilon}{\sqrt{\Delta t}} \right) \Delta t
\\

&= f(\boldsymbol{x}_t, t) \Delta t +  G(\boldsymbol{x}_t, t) \left( \boldsymbol{u}(\boldsymbol{x}_t, t) 
+ \delta \boldsymbol{u} \right) \Delta t
\\
\end{aligned}
$$

where

$$
\delta \boldsymbol{u} = \dfrac{1}{\sqrt{\rho}} \dfrac{\epsilon}{\sqrt{\Delta t}}
$$

<br><br><br>

# Cost Function

$$
V(\boldsymbol{x}_t, t) = \underset{\mathbb{u}}{\operatorname{\min}} \; \mathbb{E}_{\mathbb{Q}} \left[ \phi (\boldsymbol{x}_T, T) + \int_{t}^T \left( q(\boldsymbol{x}_t, t) + \dfrac{1}{2} \boldsymbol{u}(\boldsymbol{x}_t, t)^{\top} R (\boldsymbol{x}_t, t) \boldsymbol{u}(\boldsymbol{x}_t, t) \right) dt \right]
$$

where

- $\phi (\boldsymbol{x}_T, T)$ : final terminal cost
- $q(\boldsymbol{x}_t, t)$ : state-dependent running cost
- $R (\boldsymbol{x}_t, t)$ : positive definite matrix
- $\mathbb{E}_{\mathbb{Q}}$ : expectation over trajectories taken with respect to the controlled dynamics of the system
- $\mathbb{E}_{\mathbb{P}}$ : expectation over trajectories taken with respect to the uncontrolled dynamics of the system

<br><br><br>

# 1. Stochastic Optimal Control Problem

$$
V(\boldsymbol{x}_t, t) = \underset{\mathbb{u}}{\operatorname{\min}} \; \mathbb{E}_{\mathbb{Q}} \left[ \phi (\boldsymbol{x}_T, T) + \int_{t}^T \left( q(\boldsymbol{x}_t, t) + \dfrac{1}{2} \boldsymbol{u}(\boldsymbol{x}_t, t)^{\top} R (\boldsymbol{x}_t, t) \boldsymbol{u}(\boldsymbol{x}_t, t) \right) dt \right]
$$

subject to

$$
d\boldsymbol{x} = \left( f(\boldsymbol{x}_t, t) + G(\boldsymbol{x}_t, t) \boldsymbol{u}_t(\boldsymbol{x}_t, t) \right) dt + B(\boldsymbol{x}_t, t) d\boldsymbol{w}
$$

<br><br><br>

# 2. Stochastic Hamilton–Jacobi–Bellman PDE

Stochastic Hamilton–Jacobi–Bellman equation for upper problem is given as follows

$$
-\partial_t V = q(\mathbb{x}_t, t) + f(\mathbb{x}_t, t)^{\top} V_x - \dfrac{1}{2} V_x^\top G(\mathbb{x}_t, t) R(\mathbb{x}_t, t)^{-1} G(\mathbb{x}_t, t)^{\top} V_x + \dfrac{1}{2} \text{tr}(B(\mathbb{x}_t, t) B(\mathbb{x}_t, t)^{\top} V_{xx})
$$

with the boundary condition

$$
V(\mathbb{x}_T, T) = \phi(\mathbb{x}_T, T)
$$

The optimal control is expressed in terms of the solution to this PDE as follows

$$
\mathbb{u}^*(\mathbb{x}_t, t) = - R(\mathbb{x}_t, t)^{-1} G(\mathbb{x_t, t})^{\top} V_x
$$

This backward-in-time PDE is unsolvable. So, we take into account path integral control framework.

<br><br><br>

# 3. Linearization of PDE

1. exponential transformation of the value function
2. assuming a relationship between the noise and controls, $BB^{\top} = \lambda G R^{-1} G^{\top}$

We define desirability function $\Psi (\boldsymbol{x}, t)$, exponential transform,

$$
V(\mathbb{x}, t) = - \lambda \log(\Psi(\boldsymbol{x}, t))
$$

Then we obtain the followings.

$$
\partial_t V = - \dfrac{\lambda}{\Psi} \partial_t \Psi, \quad V_x = -\dfrac{\lambda}{\Psi}\Psi_x
$$

$$
\nabla_{xx} V_{ij} 
= - \lambda \dfrac{\Psi\dfrac{\partial \Psi}{\partial \boldsymbol{x}_i \partial \boldsymbol{x}_j} 
- \dfrac{\partial \Psi}{\partial \boldsymbol{x}_i} \cdot \dfrac{\partial \Psi}{\partial \boldsymbol{x}_j}}{\Psi^2}
$$

$$
V_{xx} = - \dfrac{\lambda}{\Psi}\Psi_{xx} + \dfrac{\lambda}{\Psi^2} \Psi_x \Psi_x^\top
$$

<br>

Now we reorganize the HJB PDE

$$
\begin{aligned}
\lambda \dfrac{\partial_t \Psi}{\Psi} 

&= q - \lambda \dfrac{f^{\top} \Psi_x}{\Psi} - \dfrac{\lambda}{2} \dfrac{\Psi_x^\top}{\Psi} G R^{-1}G^{\top} \left( \lambda \dfrac{\Psi_x}{\Psi} \right) 
\\

&\quad - \dfrac{1}{2} \text{tr} \left( BB^{\top} \left( \dfrac{\lambda}{\Psi}\Psi_{xx} \right) \right) + \dfrac{\lambda}{2 \Psi^2} \text{tr}(BB^{\top} \Psi_x \Psi_x^{\top})
\end{aligned}
$$

or

$$
\partial_t \Psi = \dfrac{\Psi}{\lambda} q - f^{\top} \Psi_x - \dfrac{\lambda}{2\Psi}\Psi_x^\top G R^{-1}G^{\top} \Psi_x - \dfrac{1}{2} \text{tr} \left( BB^{\top} \Psi_{xx} \right) + \dfrac{1}{2 \Psi} B\Psi_x \Psi_x^{\top}B^{\top}
$$

Assuming

$$
BB^{\top} = \lambda G R^{-1} G^{\top}
$$

relationship between the noise and control costs of the system,

$$
\partial_t \Psi(\boldsymbol{x}, t) = \dfrac{\Psi(\boldsymbol{x}, t)}{\lambda} q(\boldsymbol{x}, t) - f(\boldsymbol{x}, t)^{\top} \Psi_x - \dfrac{1}{2} \text{tr} \left( B(\boldsymbol{x}, t)B(\boldsymbol{x}, t)^{\top} \Psi_{xx} \right)
$$

This particular partial differential equation is known as the backward Chapman–Kolmogorov PDE

Under ttat assumption, the two terms cancel to make PDE linear. this assumption means that the noise in any given state is proportional to the control that can be exercised over that state.

In order for the connection between control authority and noise to hold, there are two requirements.

1. stochasticity has to enter the dynamics via the control channel
2. control cost has to be tuned properly to match the variance of the stochastic forces.

why...?

<br><br><br>

# 4. Feynman–Kac theorem

The Feynman-Kac formula relates linear PDEs to path integrals.

The solution of PDE by Feynman-Kac formula is path integral from

$$
\begin{aligned}
\Psi(\boldsymbol{x}_{t_0}, t_0)

&= \mathbb{E}_{\mathbb{P}} \left[ \exp \left( -\dfrac{1}{\lambda} \int_{t_0}^T q(\boldsymbol{x}_t, t) \; dt \right) \Psi(\boldsymbol{x}_{T}, T) \right]
\\

&= \mathbb{E}_{\mathbb{P}} \left[ \exp \left( -\dfrac{1}{\lambda} \int_{t_0}^T q(\boldsymbol{x}_t, t) \; dt \right) \exp \left(-\dfrac{1}{\lambda} \phi(x_T) \right) \right]
\\

&= \mathbb{E}_{\mathbb{P}} \left[ \exp \left( -\dfrac{1}{\lambda} \left( \phi(x_T) + \int_{t_0}^T q(\boldsymbol{x}_t, t) \; dt \right) \right) \right]
\\

&= \mathbb{E}_{\mathbb{P}} \left[ \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \right]
\end{aligned}
$$

where

$$
\begin{aligned}
\mathcal{S}(\tau) &= \phi (\boldsymbol{x}_T, T) + \int_{t_0}^T q(\boldsymbol{x}_t, t) dt \\
&\approx \phi (\boldsymbol{x}_T) + \sum_{i = 1}^N q (\boldsymbol{x}_t, t) \Delta t \\
\end{aligned}
$$

is the cost to go of the state-dependent cost of a trajectory

$N = \dfrac{T -t}{\Delta t}$

Now we have two interesting points

1. all of the terms are forward-in-time processes
2. expectation is with respect to the uncontrolled dynamics of the system, and the control costs have completely disappeared

<br><br><br>

# 5. Path Integral

we can compute the gradient of Ψ with respect to the initial state xt0 analytically.

Taking the gradient, we obtain the following, path integral form of optimal control,

$$
\boldsymbol{u}^* dt
= \boldsymbol{\mathcal{G}}(\boldsymbol{x}_{t_0}, t_0) \dfrac{\mathbb{E}_{\mathbb{P}} \left[ \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) B_c(\boldsymbol{x}_{t_0}, t_0) d\boldsymbol{w} \right]}{\mathbb{E}_{\mathbb{P}} \left[ \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \right]} \\
$$

where

$$
G(x_t, t) =
    R(\boldsymbol{x}_t, t)^{-1} G_c(\boldsymbol{x}_t, t)^\top
    \left[G_c(\boldsymbol{x}_t, t)
    R(\boldsymbol{x}_t, t)^{-1}
    G_c(\boldsymbol{x}_t, t)^\top
\right]^{-1}
$$

The fundamental difference between this form of the optimal control and classical optimal control theory is that, instead of relying on a backward-in-time process, this formula requires the evaluation of an expectation that can be approximated using forward sampling of stochastic differential equations.

Discretization

$$
\boldsymbol{u}(\boldsymbol{x}_{t_0}, t_0)^* \Delta t
= \boldsymbol{\mathcal{G}}(\boldsymbol{x}_{t_0}, t_0) \dfrac{\mathbb{E}_{\mathbb{P}} \left[ \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \left( d\boldsymbol{x}_{t_0}^{(c)} - f_c(\boldsymbol{x}_{t_0}, t_0) \Delta t \right) \right]}{\mathbb{E}_{\mathbb{P}} \left[ \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \right]} \\
$$

or

$$
\boldsymbol{u}(\boldsymbol{x}_{t_0}, t_0)^*
= \boldsymbol{\mathcal{G}}(\boldsymbol{x}_{t_0}, t_0) \dfrac{\mathbb{E}_{\mathbb{P}} \left[ \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \left( \dfrac{d\boldsymbol{x}_{t_0}^{(c)}}{\Delta t} - f_c(\boldsymbol{x}_{t_0}, t_0) \right) \right]}{\mathbb{E}_{\mathbb{P}} \left[ \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \right]} \\
$$

<br><br><br>

# 6. Importance Sampling

$$
\begin{aligned}
\boldsymbol{u}(\boldsymbol{x}_{t}, t)^*

&= \boldsymbol{\mathcal{G}}(\boldsymbol{x}_{t}, t) \dfrac{\mathbb{E}_{p} \left[ \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \left( \dfrac{d\boldsymbol{x}_{t_0}^{(c)}}{\Delta t} - f_c(\boldsymbol{x}_{t}, t) \right) \right]}{\mathbb{E}_{p} \left[ \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \right]}
\\

&= \boldsymbol{\mathcal{G}}(\boldsymbol{x}_{t_0}, t_0) \dfrac{\displaystyle\int \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \left( \dfrac{d\boldsymbol{x}_{t_0}^{(c)}}{\Delta t} - f_c(\boldsymbol{x}_{t}, t) \right) \mathbf{p}(\tau) d\tau}{\displaystyle \int \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \mathbf{p}(\tau)d\tau}
\\

&= \boldsymbol{\mathcal{G}}(\boldsymbol{x}_{t_0}, t_0) \dfrac{\displaystyle\int \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \left( \dfrac{d\boldsymbol{x}_{t_0}^{(c)}}{\Delta t} - f_c(\boldsymbol{x}_{t}, t) \right) \left(\dfrac{\mathbf{q}(\tau)}{\mathbf{q}(\tau)} \right)\mathbf{p}(\tau) d\tau}{\displaystyle\int \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \left(\dfrac{\mathbf{q}(\tau)}{\mathbf{q}(\tau)} \right) \mathbf{p}(\tau)d\tau}
\\

&= \boldsymbol{\mathcal{G}}(\boldsymbol{x}_{t_0}, t_0) \dfrac{\mathbb{E}_{\mathbf{q}} \left[ \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \left( \dfrac{d\boldsymbol{x}_{t_0}^{(c)}}{\Delta t} - f_c(\boldsymbol{x}_{t}, t) \right) \left(\dfrac{\mathbf{p}(\tau)}{\mathbf{q}(\tau)} \right) \right]}{\mathbb{E}_{p} \left[ \exp \left( -\dfrac{1}{\lambda} S(\tau) \right) \left(\dfrac{\mathbf{p}(\tau)}{\mathbf{q}(\tau)} \right) \right]}
\\

\end{aligned}
$$

Probability of the trajectory

$$
p(\boldsymbol{x}_{t_0}, \boldsymbol{x}_{t_1}, \dots, \boldsymbol{x}_{t_N}) = \prod_{i=1}^N p(\boldsymbol{x}_{t_i} | \boldsymbol{x}_{t_{i-1}}) 
$$

$$
p(\boldsymbol{x}_{t_0}, \boldsymbol{x}_{t_1}, \dots, \boldsymbol{x}_{t_N})

= Z(\tau)^{-1} \exp \left( -\dfrac{\Delta t}{2} \sum_{i=1}^N (z_i - \mu_i)^{\top} \Sigma_i^{-1} (z_i - \mu_i) \right)
$$

where

$$
Z(\tau) = \prod_{i=1}^N (2\pi)^{n/2} \vert \Sigma_i \vert^{1/2}, \quad \Sigma_i = B_c(\boldsymbol{x}_t, t_i) B_c(\boldsymbol{x}_t, t_i)^{\top} \Delta t
\\

z_i = \dfrac{d\boldsymbol{x}_{t_i}^{(c)}}{\Delta t} -f^{(c)}(\boldsymbol{x}_{t_i}, t_i), \quad \mu_i = G^{(c)}(\boldsymbol{x}_{t_i}, t_i) \boldsymbol{u}(\boldsymbol{x}_{t_i}, t_i)
$$

Let's define $p(\tau)$ be the probability density function for trajectories under the uncontrolled discrete time dynamics

$$

$$

<br><br><br>

# Final

Define

$$
\tilde{S}(\tau) = \phi(\boldsymbol{x}_T) + \sum_{j=1}^N \tilde{q}(\boldsymbol{x}, \boldsymbol{u}, d\boldsymbol{x})
$$

$$
\begin{aligned}
\boldsymbol{u}(\boldsymbol{x}_{t}, t)^*

&= \boldsymbol{\mathcal{G}}(\boldsymbol{x}_{t}, t) \dfrac{\mathbb{E}_{\mathbf{q}} \left[ \exp \left( -\dfrac{1}{\lambda} \tilde{S}(\tau) \right) \left( \dfrac{d\boldsymbol{x}_{t}^{(c)}}{\Delta t} - f_c(\boldsymbol{x}_{t}, t) \right) \right]}{\mathbb{E}_{\mathbf{q}} \left[ \exp \left( -\dfrac{1}{\lambda} \tilde{S}(\tau) \right) \right]}
\\

&= \boldsymbol{\mathcal{G}}(\boldsymbol{x}_{t}, t) G_c(\boldsymbol{x}_t, t) \boldsymbol{u}(\boldsymbol{x}_t, t)

+\boldsymbol{\mathcal{G}}(\boldsymbol{x}_{t}, t) \dfrac{\mathbb{E}_{\mathbf{q}} \left[ \exp \left( -\dfrac{1}{\lambda} \tilde{S}(\tau) \right) B_c(\boldsymbol{x}_t, t) \dfrac{\epsilon}{\sqrt{\Delta t}} \right]}{\mathbb{E}_{\mathbf{q}} \left[ \exp \left( -\dfrac{1}{\lambda} \tilde{S}(\tau) \right) \right]}
\\

\end{aligned}
$$

<br><br><br>

$$
\begin{aligned}
\boldsymbol{u}(\boldsymbol{x}_{t}, t)^*

&= \boldsymbol{u}(\boldsymbol{x}_{t}, t)
+ \dfrac{\mathbb{E}_{\mathbf{q}} \left[ \exp \left( -\dfrac{1}{\lambda} \tilde{S}(\tau) \right) \delta \boldsymbol{u} \right]}{\mathbb{E}_{\mathbf{q}} \left[ \exp \left( -\dfrac{1}{\lambda} \tilde{S}(\tau) \right) \right]}
\\

&\approx \boldsymbol{u}(\boldsymbol{x}_{t}, t)
+ \dfrac{\sum_{k=1}^K \exp \left( -\dfrac{1}{\lambda} \tilde{S}(\tau_{i, k}) \right) \delta \boldsymbol{u}_{i, k}}{\sum_{k=1}^K \exp \left( -\dfrac{1}{\lambda} \tilde{S}(\tau_{i, k}) \right)}
\\

\end{aligned}
$$

where

- $K$: number of random samples (rollouts)
- $S(\tau_{i, k})$ :  cost to go of the $k$ th rollout from time $t_i$ onward

This expression is simply a reward-weighted average of random variations in the control input.

# Limitation

MPPI use single mode gaussian distribution as action, which causes insufficiency of capturing complicated humanoid motion.

MPPI는 결국 최적 제어 입력을 구하기 위해 여러 개의 샘플 trajectory (K개)들을 생성하고, 이를 기반으로 control을 업데이트합니다.
이 샘플들은 단일 모드 Gaussian 분포 (보통 평균은 현재 제어 입력, 공분산은 noise scaling)에 따라 생성됩니다.
즉, $\delta u \sim \mathcal{N}(0, \Sigma)$ 이런 식으로 noise를 넣습니다.

직접적으로는 importance sampling 기반의 rollout 방식 (Section 6) 때문입니다. 간접적으로는 **Path Integral formulation (Section 5)**의 Monte Carlo approximation에서 파생된 구현상의 제약입니다.

# Reference

- [Aggressive driving with model predictive path integral control](https://www.scribd.com/document/832363051/Aggressive-driving-with-model-predictive-path-integral-control)
- [Model Predictive Path Integral Control: From Theory to Parallel Computation](https://arc.aiaa.org/doi/pdf/10.2514/1.G001921)
