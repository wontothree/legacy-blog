---
title: "[MP] Week13"
categories:
  - ECE
  - MP
tags:
  - 2-1
toc: true
---


## 1's complement and 2's complement

- +2를 -2로 어떻게 만들 수 있을까? 1의 보수: 1111(2) - 0010(2) = 1101(-2)
- 2의 보수: 1101(2) + 1 = 1110 -> 같은 하드웨어를 사용할 수 있다는 장점이 있다. 동일한 하드웨어로 덧셈기와 뺄셈기를 구현할 수 있다.
- 4 + 3 = 7, 4 + (-3) = 1 -> 4 + (3' + 1) = 1

## 2's Complement Adder/Subtractor

- 한 input이 1이면 XOR gate는 다른 input의 inverter 역할을 한다. 반대로 한 input이 0이면 다른 input이 0일 때 0 1일 때 1
- 2의 보수를 이용해서 음수를 표현한다.
- 관심이 있다면 boost algorithm을 이용해서 찾아보길 바란다.

## 과제 안내

- Test Bench는 시뮬레이터에서 테스트하기 위한 것이다.
- instruction memory에 접근할 때는 32bits로 정렬되어 있어야 한다.
- 돌려야 할 코드는 과제 1로 했던 코드다. 제대로 된 어셈블리 코드를 랄스에 넣고 돌리면 변환이 된다. (인스트럭션 메모리 바꾸는 것)
- instruction memory.mem을 바꿔야 한다.
- 여러 시뮬레이션을 웨이브 폼 뷰어로 볼 수 있다.

## Introduction to Deep Learning

- CNN은 내적을 열심히 하는데 내적의 실체가 곱셈이라고 했을 때
- 사람의 뇌를 잘 이해하고 그것을 모방하여 만들다. 선형적인 분류를 할 수 있다. XOR로 대표되는 non linear한 것들을 다룰 수 없다.
- G Hinton이 지금의 Deep Learning의 문을 연 사람이다. Perceptron을 여러 번 중첩하면 non linear한 것들을 다룰 수 있더라.
- 2012년 Deep Neural Network로 혁신적인 결과를 냈다. 이 시점부터 대회에서 딥러닝을 한 것들이 많아지더니 지금은 다 딥러닝이다.
- Perceptron은 1950년까지 거슬러 올라간다.

## Perceptron

- Cluster가 있는 것들 즉 linear한 것들은 다룰 수가 있지만 non linear한 것들은 다룰 수 없다.
- non linear한 것들을 어떻게 classification할 수 있을까?

## Multi-Layer Perceptron

- 하나 하나의 뉴런들이 Multi-Layer로 되어 있다.
- 제프리 힌턴

## Beyond MLP and the Challenges

- 첫 번째 뉴런에서 나온 결과를 다음 뉴런에 입력으로 넣는 구조를 만들어 Layer 층을 쌓으면 복잡한 문제를 풀 수 있다.
- Hidden Layer를 3층 쌓은 것이다.
- 곱해서 누적한 후 결과를 출력한다. 각각의 값을 더해서 1이 넘지 않도록. output layer로 나온 것은 확률적인 것이다.
- 고양이 사진이 pixel로 되어 있는데 각각을 계산하는 것이다.
- 분류할 수 있는 클래스의 종류가 4개면 output layer가 네 개다.
- MLP의 문제는
- 하나의 뉴런이 그 전 층에 모든 뉴런과 연결된 것이 아니라 일부와만 연결된다.
- 마지막에 사라, 이영민, 홍길동 중에 구분한다.
- 만약 올바른 결과가 나오지 않는다면 문제의 원인을 찾기 위해 wight에 대한 gredient를 찾는다.
- 학습의 실체는 각 layer의 weight 값을 구하는 것이다. 수학적 실체는 weight의 gredient를 미분하는 것이다.
- 모든 탐색 공간에서 최적값은 아니지만 주어진 것에서 최적값을 찾는 식으로 주어진 공간에서 최적값을 찾아나간다
- 정답을 주어야 했지만

## DNN

- Face Detection에서 Face에서 Recognision으로 수정한다.
- GPU가 나온 것도 Deep Learning 때문이다. CPU로는 계산력이 만족스럽지 않아서다. GPU의 killer application이 Deep Learning이었다.
- GPU, BIG DATA, Algorithm 삼박자가 맞아서 Deep Learning이 나올 수 있었다.
- Machine Learning에서 귀납적인 방법을 취하는 것이 Deep Learning이다. 개념이 없이 엄청나게 많은 유형의 문제를 풀어서 실력을 올리는 것과 같다.
- feature을 제공하지 않아도 이미지만 많이 제공하면 되더라. Supervised Learning
- 자연어 처리, 이미지 등 그 값이 나오도록 label 값을 수정해나가면 된다.

## Unsupervised Learning

## Reinforcement Learning

- 알파고, 자율주행차
- feedback
- CNN은 시험범위다.
